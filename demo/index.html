<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-TCWJ0JB5KY"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-TCWJ0JB5KY');
    </script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <meta charset="UTF-8">
    <title>Label Delay In Online Continual Learning</title>
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <style>
        .datacard.category-42 .datacard-background {
            fill: #c5c5c3;
            stroke: #000;
            stroke-width: 1px;
        }
        .datacard.category-42 circle {
            fill: #797979;
            stroke: #303030;
            stroke-width: 2px;
        }

        .datacard.category-0 .datacard-background {
            fill: #fce5cd;
            stroke: #e69138;
            stroke-width: 1px;
        }
        .datacard.category-0 circle {
            fill: #f9cb9c;
            stroke: #e69138;
            stroke-width: 2px;
        }


        .datacard.category-1 .datacard-background {
            fill: #c9daf8;
            stroke: #3c78d8;
            stroke-width: 1px;
        }
        .datacard.category-1 circle {
            fill: #a4c2f4;
            stroke: #3c78d8;
            stroke-width: 2px;
        }

        .datacard.category-2 .datacard-background {
            fill: #d9ead3;
            stroke: #6aa84f;
            stroke-width: 1px;
        }
        .datacard.category-2 circle {
            fill: #b6d7a8;
            stroke: #6aa84f;
            stroke-width: 2px;
        }

        .predcard-background {
            fill: #f0f0f0;
            stroke: #000;
            stroke-width: 1px;
            stroke-dasharray: 5, 5;
        }

        body {
            font-family: 'EB Garamond', serif;
        }

        .svg-container {
            width: 90%;
            overflow: hidden;
            /* height: 90vh; */
            display: flex;
            margin: auto;
            justify-content: center;
            padding: 1em;
        }

        .svg-container.prediction-container {
            max-height: 15vh;
        }

        .svg-container.similarity-container {
            max-height: 60vh;
        }

        .control-panel {
            width: 90%;
            margin: auto;
            text-align: center;
            font-size: 2vw;
            margin-top: 1em;
            display: flex;
            justify-content: space-around;
        }

        .control-panel button {
            font-size: 2vw;
            /* margin: 0.5em; */
            /* padding: 0.5em; */
            border-radius: 0.5em;
            width: 19%;
            border: none;
            cursor: pointer;
            font-family: 'EB Garamond', serif;
        }

        .control-panel button:hover:enabled {
            filter: brightness(.9);
        }
        .control-panel button:active:enabled {
            filter: brightness(.8);
        }


        .low-level-controls {
            /* display: flex; */
            /* justify-content: space-around; */
            text-align: right;
            width: 45%;
            font-size: 1.5vw;
        }

        #addCategory0 {
            background-color: #fce5cd;
            color: #e69138;
        }
        #addCategory0:hover {
            background-color: #f9cb9c;
        }
        #addCategory0:active, #addCategory0.active  {
            background-color: #fbb167;
        }

        #addCategory1 {
            background-color: #c9daf8;
            color: #3c78d8;
        }
        #addCategory1:hover {
            background-color: #a4c2f4;
        }
        #addCategory1:active, #addCategory1.active  {
            background-color: #8db3f4;
        }

        #addCategory2 {
            background-color: #d9ead3;
            color: #6aa84f;
        }
        #addCategory2:hover {
            background-color: #b6d7a8;
        }
        #addCategory2:active, #addCategory2.active  {
            background-color: #a2d08c;
        }

        #trainModel {
            background: white;
            border: 2px solid black;
        }

        h1 {
            text-align: center;
        }

        h2 {
            text-align: center;
        }

        h3 {
            margin-bottom: 0.25em;
        }

        p {
            margin-top: 0.25em;
        }

        #explanation {
            width: 70%;
            margin: auto;
            margin-top: 20vh;
        }

        .slider {
            -webkit-appearance: none; /* Override default styles */
            appearance: none;
            width: 50%; /* Full width */
            height: 3px; /* Slider line thickness */
            background: black; /* Slider line color */
            outline: none; /* Remove outline */
            opacity: 1; /* Make slider fully visible */
            margin: 0px 20px;
        }

        .slider::-webkit-slider-thumb {
            -webkit-appearance: none; /* Override default styles */
            appearance: none;
            width: 20px; /* Set the handle size */
            height: 20px; /* Set the handle size */
            background: white; /* Handle color */
            border: 3px solid black; /* Remove border */
            cursor: pointer; /* Cursor on hover */
            border-radius: 50%; /* Make it a circle */
        }

        button {
            -webkit-user-select: none; /* Safari */
            -moz-user-select: none; /* Firefox */
            -ms-user-select: none; /* Internet Explorer/Edge */
            user-select: none; /* Non-prefixed version, currently supported by Chrome, Opera, and Edge */
        }


        select {
            width: 40%;
            font-size: 1.5vw;
            /* padding: 0.5em; */
            border-radius: 0.5em;
            border: 2px solid gray;
            font-family: 'EB Garamond', serif;
            text-align-last: center;
            margin: 0.1em;
        }

        input[type=number] {
            width: 38.5%;
            font-size: 1.5vw;
            /* padding: 0.5em; */
            border-radius: 0.5em;
            border: 2px solid gray;
            font-family: 'EB Garamond', serif;
            text-align: center;
            margin: 0.1em;
        }

        select:hover {
            border: 2px solid #3c78d8;
            filter: brightness(0.9);
        }



    </style>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.7.1/jszip.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/seedrandom/3.0.5/seedrandom.min.js"></script>
    <script src="resnet18.js"></script>
    <script src="mobilenetv2.js"></script>
    <script src="mobilenetv3.js"></script>
    <script src="cnn.js"></script>
    <script src="linear.js"></script>
    <script src="utils.js"></script>

</head>

<body>
    <h1>Label Delay in Online Continual Learning</h1>

    <div class="svg-container prediction-container">
        <svg id="prediction-card" style="width: 25%;" viewBox="0 0 255 150"></svg>
    </div>
    <div class="control-panel">
        <div style="text-align: center; width: 100%;">
            <!-- disabled until model is not loaded-->
            <button id="initializeWebcam" disabled>Loading Model</button>
            <button id="startStream" disabled>Start Data Stream</button>
            <button id="loadStream" disabled>Load Stream</button>
            <button id="saveStream" disabled>Save Stream</button>
        </div>
    </div>
    <!-- <div class="svg-container" style="visibility: hidden;"> -->
    <div class="svg-container similarity-container">
        <svg id="similarity-grid" viewBox="0 0 1600 700"></svg>
    </div>
    <div class="control-panel">
        <button id="addCategory0" class="addCategoryButton">Add Category 1</button>
        <button id="addCategory1" class="addCategoryButton" >Add Category 2</button>
        <button id="addCategory2" class="addCategoryButton">Add Category 3</button>
        <button id="trainModel">Update Model</button>
    </div>
    <div class="control-panel">
        <div class="low-level-controls">
            Delay (Pending Entry size):
            <input type="number" id="pending-size-input" value="3" min="1" max="100" title="
            This is the number of steps that the newest sample will be delayed before being available for training.

            The delay is implemented by moving the newest sample through the Pending Entries segment before it can be accessed for training.
            " onkeydown="return false;">
            <!-- <input type="number" id="pending-size-input" value="3" min="1" max="100" title="
This is the number of steps that the newest sample will be delayed before being available for training.

The delay is implemented by moving the newest sample through the Pending Entries segment before it can be accessed for training.
            "> -->
            <br>
            Architecture:
            <select id="arch-select" title="
Select the architecture of the model.
The model is either randomly initialized with a fixed seed for reproducibility,
or it is pretrained on ImageNet and fine-tuned on the current task.
WARNING: Selecting a pretrained model will reset the learned features.
            ">
                <option value="none" disabled>Select Architecture</option>
                <option value="linear" selected>Linear</option>
                <option value="resnet18">ResNet18</option>
                <option value="cnn_small">CNN Small</option>
                <option value="cnn_base">CNN Base</option>
                <option value="cnn_large">CNN Large</option>
                <option value="mobilenetv2">MobileNetV2 (ImageNet pretrained)</option>
                <option value="mobilenetv3">MobileNetV3 (ImageNet pretrained)</option>
            </select>
            <br>
            Optimizer:
            <select id="optimizer-select">
                <option value="none" disabled>Select Optimizer</option>
                <option value="adam">Adam</option>
                <option value="momentum">Momentum (0.9)</option>
                <option value="sgd" selected>SGD</option>
            </select>
            <br>
            Learning Rate:
            <select id="learning-rate-select">
                <option value="none" disabled>Select Learning Rate</option>
                <option value="0.00001">0.00001</option>
                <option value="0.0001">0.0001</option>
                <option value="0.001">0.001</option>
                <option value="0.01" selected>0.01</option>
                <option value="0.1">0.1</option>
            </select>
            <br>
            <!-- Random Seed:
            <select id="random-seed-select" max="100000" title="
The random seed is used to initialize the model parameters.
The same seed will result in the same initialization.
            ">
                <option value="42" selected>42</option>
                <option value="1337">1337</option>
                <option value="12345">12345</option>
            </select> -->
            # Parameter updates per timestep:
            <select id="updates-per-timestep-select">
                <option value="none" disabled>Select Updates per Timestep</option>
                <option value="1" selected>1</option>
                <option value="2">2</option>
                <option value="3">3</option>
                <option value="4">4</option>
                <option value="5">5</option>
            </select>

        </div>
        <div class="low-level-controls">
            Memory Buffer size:
            <input type="number" id="memory-size-input" value="10" min="1" max="300" title="
This is the number of samples that can be stored in the memory buffer.
In each training step, two samples are selected from the memory buffer for training.
            " onkeydown="return false;">
            <br>
            $X_1$ selection policy:
            <select id="x1-policy-select" title="
Select the policy for selecting the first sample for each training step.
            ">
                <option value=null disabled select>X_1 selection policy</option>
                <option value="random" selected>Random</option>
                <option value="newest">Newest</option>
                <option value="second-newest">Second Newest</option>
                <option value="iwm">Importance Weighted Memory</option>
            </select>
            <br>
            $X_2$ selection policy:
            <select id="x2-policy-select" title="
Select the policy for selecting the second sample for each training step.
            ">
                <option value=null disabled select>X_2 selection policy</option>
                <option value="random2" selected>Random</option>
                <option value="newest">Newest</option>
                <option value="second-newest">Second Newest</option>
                <option value="iwm">Importance Weighted Memory</option>
            </select>
            <br>
            Train on newest sample:
            <select id="train-on-new-select">
                <option value=null disabled select>Train on newest sample</option>
                <option value=true selected>True</option>
                <option value=false>False</option>
            </select>
            <br>
            Update features after training:
            <select id="features-select">
                <option value=null disabled select>Update features</option>
                <option value=true selected>True</option>
                <option value=false>False</option>
            </select>
        </div>
    </div>
    <div class="control-panel">
        <div style="text-align: center; width: 100%;">
            Limit refresh rate:
            1 FPS
            <input type="range" min="1" max="30" value="30" class="slider" id="fpsSlider">
            30 FPS
        </div>
    </div>


    <div id="video-container" style="visibility: hidden;">
        <video id="webcam" autoplay style="display: none;"></video>
        <canvas id="aux-canvas" style="display: none;"></canvas>
    </div>
    <script src="demo_fast.js"></script>
    <div id="explanation">
        <!-- Hidden file input for loading images -->
        <input type="file" id="loadStreamInput" style="display:none" />

        <h2>
            Manual:
        </h2>
        <p>
            This demo shows an instance of a realistic online learning problem.
            The stream of data points is collected from the webcam, and therefore it is under your full control how much the data-distribution is shifting.

            When you press one of the "Add Category" buttons, the newest sample will be associated with the corresponding label.
            There is no restriction what you can teach to your computer, everything is computed locally on your device, i.e. no data is sent to the server at all.

            In every step the data flows from the top of the Pending Entries to the bottom, and if the data point is labeled, it will be moved to the Memory Buffer.

            As you can see, there are a few slots in the Pending Entries, which means that
            the newest sample will not be available for training until the sample does not receive it's label.

            You can train the model by pressing the "Update Model" button, which will update the model parameters based on the selected samples.
        </p>
        <p>
            The main purpose of this simulation is to highlight how label delay can affect the performance of the model.
            In the main paper, we propose the <b>Importance Weighted Memory Sampling (IWMS)</b> method, which is a compute-efficient technique that simply just reuses the feature embeddings (that were computed anyways during the forward pass) to emulate the distribution of the newest samples during the memory rehearsal.
            To show that our method truly brings benefits, we implemented a wide range of environment settings.
        </p>
        <h3>
            The Environment Settings
        </h3>
        <p>
            <ul>
                <li>The sampling rate of the stream</li>
                <li>The delay $d$ between observing the newest sample and receiving its label</li>
                <li>The memory buffer size</li>
                <li>The architecture of the model: 7 architectures, 2 pretrained</li>
                <li>The optimizer (SGD, SGD w/ momentum, Adam)</li>
                <li>The learning rate</li>
                <li>The selection policy for the first and second sample</li>
                <li>Whether to update features after each training iteration</li>
            </ul>
        </p>
        <h3>
            The Prediction Card
        </h3>
        <p>
            The prediction card can be found on the top of the page.
            It consists of three blocks: the input image, the computed features and the prediction.
            The features are computed by the backbone architecture and are always projected to a 9-dimensional space.
            In the middle block you can find the feature embeddings arranged in a 3x3 grid, where the sizes of the circles represent the values of the embeddings.
            A little technical detail: the embeddings can be in the range of $[-\inf, \inf]$, and the size of the circle sizes are always normalized to the range of $[0, 1]$ for each data point.
            Finally, the actual prediction is shown in the rightmost block by the three circles representing the class probabilities.

            If you turn your webcam on, the newest sample will be the current frame and you will see how the embeddings are changing in real-time.
            It is interesting to see how the embeddings are changing when you are moving around, or when you are changing the lighting conditions.
            Different architectures respond quite differently to the same kind of visual changes, which can be also thought of as a characteristic of the architecture and of course the pretraining.
            For example, the linear model is very sensitive to every small change, while the MobileNetV2 features (which were pretrained on ImageNet) will mostl likely change very little when you change lighting conditions or rotate the object.

            Just like the feature embeddings, the prediction values are also updated in real-time, and the color of the largest circle is the argmax of the predicted probabilities.
        </p>
        <h3>
            The Datacards
        </h3>
        <p>
            If you click on the "Start Data Stream" button, the datacards will start to flow from the top to the bottom of the pending entries (with a default Categor 1 label), and straight away get added to the memory buffer.
            This is nicely animated in the beginning, but to avoid the moving parts, once the datacards fill up the edges of the grid, you will only see the content of the datacards being swapped out (instead of moving the cards themselves).

            When you change the Pending Entry or the Memory Buffer size, new datacards will be added or removed accordingly.

            Similarly to the prediction card, the datacards are also showing the feature embeddings in a 3x3 grid.
            The color of the background of the datacard indicates the category of the sample.
        </p>
        <h3>
            The Model
        </h3>
        <p>
            By default, the model is a linear model, randomly initialized with a fixed seed for reproducibility.
            Although a linear model might be too simple to learn generalizable features, you will be surprised how well it can perform when you have a small delay between the newest sample and the labeled data.

            To explore the performance of more complex models, you can select from the following architectures:
            <ul>
                <li>ResNet18</li>
                <li>CNN Small</li>
                <li>CNN Base</li>
                <li>CNN Large</li>
                <li>MobileNetV2 (ImageNet pretrained)</li>
                <li>MobileNetV3 (ImageNet pretrained)</li>
            </ul>
            After the model selection you can start tuning the model parameters on the currently available memory samples, but be careful: the learned features are reset when the architecture is changed.
            <!-- The model is a 2-layer convnet, randomly initialized with a fixed seed for reproducibility.
            The model parameters are updated by pressing the "Update Model" button.
            The update takes a single SGD step with a learning rate of 0.001 on the two selected samples.
            The loss function is the cross-entropy loss. -->

            When you click on the "Update Model" button, a green bar will start to fill up, indicating the cycles in which the model parameters are updated (set to 3 sec).
            In every iteration, the standard Cross Entropy objective is optimized on two samples: $X_1$ and $X_2$.

        </p>
        <h3>
            Selection Policies
        </h3>
        <p>
            The selection policy for the first and second sample can be set to one of the following:
            <ul>
                <li>Random: samples are selected randomly from the memory buffer</li>
                <li>Newest: the newest sample is selected</li>
                <li>Second Newest: the second newest sample is selected</li>
                <li>Importance Weighted Memory: the nearest neighbor of the newest sample (in the feature space) is selected</li>
            </ul>
            The Importance Weighted Memory Sampling policy is a compute-efficient technique that simply just reuses the feature embeddings (that were computed anyways during the forward pass) to emulate the distribution of the newest samples during the memory rehearsal.
            This can have a significant impact on the performance of the model, especially when the newest sample is delayed for a long time.
        <h3>
            The Similarity Grid
        </h3>
        <p>
            For each pending entries ($X_i$) and memory buffer ($X_j$) sample, we first compute the cosine similarity between their embeddings:
            $$\textrm{cos}\left(f_\theta(X_i), f_\theta(X_j)\right).$$
            Second, we compute the softmax for every row, representing the probability of the IWM sampling policy selecting $X_j$:
            $$\textrm{softmax}_i = \frac{\exp(\textrm{cos}(X_i, X_j))}{\sum_{j=1}^N \exp(\textrm{cos}(X_i, X_j))}$$
            For visualization in the grid, we rescale the probabilities such that the highest probability will fill the entire cell, and the colour will match the colour of the corresponding memory buffer sample.
        </p>
    </div>


    <p style="text-align: center; margin-top: 5em;">
        Written and maintained by <a href="https://botcs.github.io/academic", style="color: #3c78d8;">
            Botos Csabi
        </a>
    </p>
</body>
</html>
